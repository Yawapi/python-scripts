#Image processing with scikit image


# Import modules from skimage
from skimage import data, color

# Load image
rocket = data.rocket()

# Convert image to grayscale
gray_scaled_rocket = color.rgb2gray(rocket) 

# Show original image
show_image(rocket, 'Original RGB image')

# Show grayscale image
show_image(gray_scaled_rocket, 'Grayscale image')

# Flip image vertically
seville_vertical_flip = np.flipud(flipped_seville)

# Flip image horizontally
seville_horizontal_flip = np.fliplr(seville_vertical_flip)

# Show resulting image
show_image(seville_horizontal_flip, 'Seville')

# Slice for red channel
red_channel = image[:, :, 0]

# Plot red histogram
plt.hist(red_channel.ravel(), bins=256)

# Add title and show histogram
plt.title('Red Histogram')
plt.show()

# Thresholding

# Import otsu threshold function
from skimage.filters import threshold_otsu

# Make image grayscale 
chess_pieces_image_gray = rgb2gray(chess_pieces_image)

# Find optimal threshold value with otsu
thresh = threshold_otsu(chess_pieces_image_gray)

# Apply thresholding to image
binary = chess_pieces_image_gray > thresh

# Show image
show_image(binary, 'Binary image')

# Import otsu threshold function
from skimage.filters import threshold_otsu

# Obtain optimal otsu global thresh value
global_thresh = threshold_otsu(page_image)

# Obtain binary image by applying global thresholding
binary_global = page_image > global_thresh

# Show binary image 
show_image(binary_global, 'Global thresholding')

# Import local threshold function
from skimage.filters import threshold_local

# Set block size to 35
block_size = 35

# Find optimal local thresholding
local_thresh = threshold_local(page_image, block_size, offset=10)

# Apply local thresholding
binary_local = page_image > local_thresh

# Show binary image
show_image(binary_local, 'Local thresholding')

# Import try all function
from skimage.filters import try_all_threshold

# Import rgb to gray convertor function 
from skimage.color import rgb2gray

# Turn fruits_image to grayscale
grayscale = rgb2gray(fruits_image)

# Use try all method on  resulting grayscale image
fig, ax = try_all_threshold(grayscale, verbose=False)

# Show  resulting plots
plt.show()

# Import threshold and gray convertor functions
from skimage.filters import threshold_otsu
from skimage.color import rgb2gray

# Turn image grayscale
gray_tools_image = rgb2gray(tools_image)

# Obtain optimal thresh
thresh = threshold_otsu(gray_tools_image)

# Obtain binary image by applying thresholding
binary_image = gray_tools_image > thresh

# Show resulting binary image
show_image(binary_image, 'Binarized image')

# Import color module
from skimage import color

# Import filters module and sobel function
from skimage.filters import sobel

# Make image grayscale
soaps_image_gray = color.rgb2gray(soaps_image)

# Apply edge detection filter
edge_sobel = sobel(soaps_image_gray)

# Show original and resulting image to compare
show_image(soaps_image, "Original")
show_image(edge_sobel, "Edges with Sobel")

# Import Gaussian filter 
from skimage.filters import gaussian

# Apply filter
gaussian_image = gaussian(building_image, multichannel=True)

# Show original and resulting image to compare
show_image(building_image, "Original")
show_image(gaussian_image, "Reduced sharpness Gaussian")

What's  contrast of this image?
Black and white clock hanging and moving Histogram of  clock's image

 histogram tell us.

Just as we saw previously, you can calculate  contrast by calculating  range of  pixel intensities i.e. by subtracting  minimum pixel intensity value from  histogram to  maximum one.

You can obtain  maximum pixel intensity of  image by using  np.max() method from NumPy and  minimum with np.min() in  console.

 image has already been loaded as clock_image, NumPy as np and  show_image() function.

# Import  required module
from skimage import exposure

# Show original x-ray image and its histogram
show_image(chest_xray_image, 'Original x-ray')

plt.title('Histogram of image')
plt.hist(chest_xray_image.ravel(), bins=256)
plt.show()

# Use histogram equalization to improve  contrast
xray_image_eq =  exposure.equalize_hist(chest_xray_image)

# Show  resulting image
show_image(xray_image_eq, 'Resulting image')

# Import  required module
from skimage import exposure

# Use histogram equalization to improve  contrast
image_eq =  exposure.equalize_hist(image_aerial)

# Show  original and resulting image
show_image(image_aerial, 'Original')
show_image(image_eq, 'Resulting image')

# Import  necessary modules
from skimage import data, exposure

# Load  image
original_image = data.coffee()

# Apply  adaptive equalization on  original image
adapthist_eq_image = exposure.equalize_adapthist(original_image, clip_limit=0.03)

# Compare  original image to  equalized
show_image(original_image)
show_image(adapthist_eq_image, '#ImageProcessingDatacamp')

# Import  module and  rotate and rescale functions
from skimage.transform import rotate, rescale

# Rotate  image 90 degrees clockwise 
rotated_cat_image = rotate(image_cat, -90)

# Rescale with anti aliasing
rescaled_with_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=True, multichannel=True)

# Rescale without anti aliasing
rescaled_without_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=False, multichannel=True)

# Show  resulting images
show_image(rescaled_with_aa, "Transformed with anti aliasing")
show_image(rescaled_without_aa, "Transformed without anti aliasing")

# Import  module and function to enlarge images
from skimage.transform import rescale

# Import  data module
from skimage import data

# Load  image from data
rocket_image = data.rocket()

# Enlarge  image so it is 3 times bigger
enlarged_rocket_image = rescale(rocket_image, 3, anti_aliasing=True, multichannel=True)

# Show original and resulting image
show_image(rocket_image)
show_image(enlarged_rocket_image, "3 times enlarged image")

# Import  module and function
from skimage.transform import resize

# Set proportional height and width so it is half its size
height = int(dogs_banner.shape[0] / 2.0)
width = int(dogs_banner.shape[1] / 2.0)

# Resize using  calculated proportional height and width
image_resized = resize(dogs_banner, (height, width),
                       anti_aliasing=True)

# Show  original and rotated image
show_image(dogs_banner, 'Original')
show_image(image_resized, 'Resized image')

# Import morphology module
from skimage import morphology

# Obtain  eroded shape 
eroded_image_shape = morphology.binary_erosion(upper_r_image) 

# See results
show_image(upper_r_image, 'Original')
show_image(eroded_image_shape, 'Eroded image')

# Import morphology module
from skimage import morphology

# Obtain  dilated image 
dilated_image = morphology.binary_dilation(world_image)

# See results
show_image(world_image, 'Original')
show_image(dilated_image, 'Dilated image')

# Import inpaint module from restoration
from skimage.restoration import inpaint

# Show  defective image
show_image(defect_image, 'Image to restore')

# Apply  restoration function to  image using  mask
restored_image = inpaint.inpaint_biharmonic(defect_image, mask, multichannel=True)
show_image(restored_image)

# Initialize  mask to remove a watermark from an image
mask = np.zeros(image_with_logo.shape[:-1])

# Set  pixels where  logo is to 1
mask[210:272, 360:425] = 1

# Apply inpainting to remove  logo
image_logo_removed = inpaint.inpaint_biharmonic(image_with_logo, 
                                                mask, 
                                                multichannel=True)

# Show  original and logo removed images
show_image(image_with_logo, 'Image with logo')
show_image(image_logo_removed, 'Image with logo removed')

# Import  module and function
from skimage.util import random_noise

# Add noise to  image
noisy_image = random_noise(fruit_image)

# Show original and resulting image
show_image(fruit_image, 'Original')
show_image(noisy_image, 'Noisy image')

# Import  module and function
from skimage.restoration import denoise_tv_chambolle

# Apply total variation filter denoising
denoised_image = denoise_tv_chambolle(noisy_image, 
                                      multichannel=True)

# Show  noisy and denoised images
show_image(noisy_image, 'Noisy')
show_image(denoised_image, 'Denoised image')

# Import bilateral denoising function
from skimage.restoration import denoise_bilateral

# Apply bilateral filter denoising
denoised_image = denoise_bilateral(landscape_image, 
                                   multichannel=True)

# Show original and resulting images
show_image(landscape_image, 'Noisy image')
show_image(denoised_image, 'Denoised image')

# Import  slic function from segmentation module
from skimage.segmentation import slic

# Import  label2rgb function from color module
from skimage.color import label2rgb

# Obtain  segmentation with 400 regions
segments = slic(face_image, n_segments= 400)

# Put segments on top of original image to compare
segmented_image = label2rgb(segments, face_image, kind='avg')

# Show  segmented image
show_image(segmented_image, "Segmented image, 400 superpixels")

# Contouring shapes
# Import  modules
from skimage import measure, data

# Obtain  horse image
horse_image = data.horse()

# Find  contours with a constant level value of 0.8
contours = measure.find_contours(horse_image, 0.8)

# Shows  image with contours found
show_image_contour(horse_image, contours)

# Make  image grayscale
image_dice = color.rgb2gray(image_dice)

# Obtain  optimal thresh value
thresh = filters.threshold_otsu(image_dice)

# Apply thresholding
binary = image_dice > thresh

# Make  image grayscale
image_dice = color.rgb2gray(image_dice)

# Obtain  optimal thresh value
thresh = filters.threshold_otsu(image_dice)

# Apply thresholding
binary = image_dice > thresh

# Find contours at a constant value of 0.8
contours = measure.find_contours(binary, level=0.8)

# Show  image
show_image_contour(image_dice, contours)

# Create list with  shape of each contour 
shape_contours = [cnt.shape[0] for cnt in contours]

# Set 50 as  maximum size of  dots shape
max_dots_shape = 50

# Count dots in contours excluding bigger than dots size
dots_contours = [cnt for cnt in contours if np.shape(cnt)[0] < max_dots_shape]

# Shows all contours found 
show_image_contour(binary, contours)

# Print  dice's number
print("Dice's dots number: {}. ".format(len(dots_contours)))

# Edge detection with Canny
# Import  canny edge detector 
from skimage.feature import canny

# Convert image to grayscale
grapefruit = color.rgb2gray(grapefruit)

# Apply canny edge detector
canny_edges = canny(grapefruit)

# Show resulting image
show_image(canny_edges, "Edges with Canny")

# Apply canny edge detector with a sigma of 1.8
edges_1_8 = canny(grapefruit, sigma=1.8)

# Apply canny edge detector with a sigma of 2.2
edges_2_2 = canny(grapefruit, sigma=2.2)

# Show resulting images
show_image(edges_1_8, "Sigma of 1.8")
show_image(edges_2_2, "Sigma of 2.2")

# Harris corner detector
# Import  corner detector related functions and module
from skimage.feature import corner_harris, corner_peaks

# Convert image from RGB-3 to grayscale
building_image_gray = color.rgb2gray(building_image)

# Apply  detector  to measure  possible corners
measure_image = corner_harris(building_image_gray)

# Find  peaks of  corners
coords = corner_peaks(measure_image, min_distance=2)

# Show original and resulting image with corners detected
show_image(building_image, "Original")
show_image_with_corners(building_image, coords)

# Find  peaks with a min distance of 2 pixels
coords_w_min_2 = corner_peaks(measure_image, min_distance=2)
print("With a min_distance set to 2, we detect a total", len(coords_w_min_2), "corners in  image.")

# Find  peaks with a min distance of 40 pixels
coords_w_min_40 = corner_peaks(measure_image, min_distance=40)
print("With a min_distance set to 40, we detect a total", len(coords_w_min_40), "corners in  image.")

# Show original and resulting image with corners detected
show_image_with_corners(building_image, coords_w_min_2, "Corners detected with 2 px of min_distance")
show_image_with_corners(building_image, coords_w_min_40, "Corners detected with 40 px of min_distance")

# Face detection
# Load  trained file from data
trained_file = data.lbp_frontal_face_cascade_filename()

# Initialize  detector cascade
detector = Cascade(trained_file)

# Detect faces with min and max size of searching window
detected = detector.detect_multi_scale(img = night_image,
                                       scale_factor=1.2,
                                       step_ratio=1,
                                       min_size=(10, 10),
                                       max_size=(200, 200))

# Show  detected faces
show_detected_face(night_image, detected)

# Load  trained file from data
trained_file = data.lbp_frontal_face_cascade_filename()

# Initialize  detector cascade
detector = Cascade(trained_file)

# Detect faces with scale factor to 1.2 and step ratio to 1
detected = detector.detect_multi_scale(img=friends_image,
                                       scale_factor=1.2,
                                       step_ratio=1,
                                       min_size=(10, 10),
                                       max_size=(200, 200))
# Show  detected faces
show_detected_face(friends_image, detected)

# Obtain  segmentation with default 100 regions
segments = slic(profile_image)

# Obtain segmented image using label2rgb
segmented_image = label2rgb(segments, profile_image, kind='avg')

# Detect  faces with multi scale method
detected = detector.detect_multi_scale(img=segmented_image, 
                                       scale_factor=1.2, 
                                       step_ratio=1, 
                                       min_size=(10, 10), max_size=(1000, 1000))

# Show  detected faces
show_detected_face(segmented_image, detected)

# Detect faces
detected = detector.detect_multi_scale(img=group_image, 
                                       scale_factor=1.2, step_ratio=1, 
                                       min_size=(10, 10), max_size=(100, 100))
# For each detected face
for d in detected:  
    # Obtain  face rectangle from detected coordinates
    face = getFaceRectangle(d)
    
    # Apply gaussian filter to extracted face
    blurred_face = gaussian(face, multichannel=True, sigma = 8)
    
    # Merge this blurry face to our final image and show it
    resulting_image = mergeBlurryFace(group_image, blurred_face) 
show_image(resulting_image, "Blurred faces")

# Import  necessary modules
from skimage.restoration import denoise_tv_chambolle, inpaint
from skimage.transform import rotate

# Transform  image so it's not rotated
upright_img = rotate(damaged_image, 20)

# Remove noise from  image, using  chambolle method
upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)

# Reconstruct  image missing parts
mask = get_mask(upright_img)
result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)

show_image(result)



